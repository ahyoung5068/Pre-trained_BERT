{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"tI9QXWWWYzGs","executionInfo":{"status":"ok","timestamp":1645901745164,"user_tz":-540,"elapsed":4705,"user":{"displayName":"한민아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00579567117411198235"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"v9d2uAuoYzGx","executionInfo":{"status":"ok","timestamp":1645901745165,"user_tz":-540,"elapsed":6,"user":{"displayName":"한민아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00579567117411198235"}}},"outputs":[],"source":["class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-ayPqfPgYzGy","executionInfo":{"status":"ok","timestamp":1645901745166,"user_tz":-540,"elapsed":5,"user":{"displayName":"한민아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00579567117411198235"}}},"outputs":[],"source":["class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen, vocab_size, embed_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, trainable=True)\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim, trainable=False)\n","\n","    def call(self, x):\n","        maxlen = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"]},{"cell_type":"code","source":[""],"metadata":{"id":"1VxvDcNYY32t"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"trans_cls.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}